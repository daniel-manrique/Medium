---
title-block-banner: true
title: "Improving the analysis of cells/objects counts with zero-inflated models and brms"
subtitle: "An approach using Bayesian regression with brms"
date: today
date-format: full
author: 
  - name: "Daniel Manrique-Castano"
    orcid: 0000-0002-1912-1764
    degrees:
      - PhD
    affiliation: 
      - name: Univerisity Laval 
        department: Psychiatry and Neuroscience
        group: Laboratory of neurovascular interactions 
note: "GitHub: https://daniel-manrique.github.io/"
keywords: 
  - zero-inflated models
  - cell counts
  - Bayesian modeling
  - brms 
   
license: "CC BY"

format:
   pdf: 
    toc: true
    number-sections: true
    colorlinks: true
   html:
    code-fold: true
    embed-resources: true
    toc: true
    toc-depth: 2
    toc-location: left
    number-sections: true
    theme: spacelab

knitr:
  opts_chunk: 
    warning: false
    message: false
    
csl: science.csl
bibliography: References.bib
---

# Load libraries and themes

First, let's load the necessary libraries and create a visual theme for our plots.

```{r}
#| label: LoadPack
#| include: true
#| warning: false
#| message: false

library(ggplot2)
library(brms)
library(ggdist)
library(easystats)
library(dplyr)
library(modelr)
library(patchwork)
library(tibble)
library(tidybayes)

logit2prob <- function(logit){
  odds <- exp(logit)
  prob <- odds / (1 + odds)
  return(prob)
}

Plot_theme <- theme_classic() +
  theme(
      plot.title = element_text(size=18, hjust = 0.5, face="bold"),
      plot.subtitle = element_text(size = 10, color = "black"),
      plot.caption = element_text(size = 12, color = "black"),
      axis.line = element_line(colour = "black", size = 1.5, linetype = "solid"),
      axis.ticks.length=unit(7,"pt"),
     
      axis.title.x = element_text(colour = "black", size = 16),
      axis.text.x = element_text(colour = "black", size = 16, angle = 0, hjust = 0.5),
      axis.ticks.x = element_line(colour = "black", size = 1),
      
      axis.title.y = element_text(colour = "black", size = 16),
      axis.text.y = element_text(colour = "black", size = 16),
      axis.ticks.y = element_line(colour = "black", size = 1),
      
      legend.position="right",
      legend.direction="vertical",
      legend.title = element_text(colour="black", face="bold", size=12),
      legend.text = element_text(colour="black", size=10),
      
      plot.margin = margin(t = 10,  # Top margin
                             r = 2,  # Right margin
                             b = 10,  # Bottom margin
                             l = 10) # Left margin
      ) 
```

One of the things we biomedical researchers do the most is count. For the past three years, one of my main tasks has been to count cells in different regions of the brain. In many scenarios, the number of cells is overwhelming, hundreds or thousands in small regions. Still, there are other circumstances where cells are low, and even we may not find any of our cells of interest. In the former case, many of us would agree that using linear models (based on a normal distribution) is an acceptable. It is usually not the case but, at least, is a logical framework. However, when the counts are close to zero, or even have many zeros, the linear model (those t-tests we run in GraphPad) become meaningless. As scientists, we can do much better, and my goal is to make this post a good starting point.

# What the issue couting zeros?

The following graph by [@baraibar2020] shows low cell counts, and in the case of the black group, we can estimate that the counting is dominated by 0 counts.

![Left: CD3+ cells by Baraibar et. al (2020) (CC-BY). (CC-BY).](Plots/2024-04-19_CountsZeroInflated/CoutingZeros.png){#fig-sample fig-align="center"}

Cases like this abound in the literature, where scientists use simple linear models for analysis. Since in most cases scientists do not share the data that support their conclusions, let's look at the problem using other data in my possession. Years ago, I counted the number of BrdU+ cells after an ischemic event in a region of the brain known as the subventricular zone (SVZ).

These are the data:

```{r}
#| label: LoadData
#| include: true
#| warning: false
#| message: false
#| column: margin

Svz_data <- read.csv("Data/CellCounts.csv")
Svz_data$Hemisphere <- factor(Svz_data$Hemisphere, levels = c("Contralateral", "Ipsilateral"))
head(Svz_data)
```

We can see that the contralateral hemisphere has a lot of null cell counts. This is how it look like in a boxplot:

```{r}
#| label: fig-EDA
#| include: true
#| warning: false
#| message: false
#| fig-cap: Cell counts by hemisphere.
#| fig-height: 5
#| fig-width: 6

ggplot(Svz_data, aes(x = Hemisphere, y = Cells)) +
  geom_boxplot() +
  labs(x = "Hemisphere", y = "Number of cells", title = "Cells by hemisphere") +
  Plot_theme +
  theme(legend.position = "top", legend.direction = "horizontal")
```

@Fig-Fig2 shows the substantial difference between the cell counts. Now, what happens if I fit a typical linear model (based on a normal distribution) to this data? Let's see. I will fit a model with the factor variable "hemisphere" as the unique predictor of the cell counts using `brms`:

```{r}
#| label: Lm_Fit
#| include: true
#| warning: false
#| message: false

lm_Fit <- brm(Cells ~ Hemisphere, 
           data = Svz_data, 
           # seed for reproducibility purposes
           seed = 8807,
           control = list(adapt_delta = 0.99),
           # this is to save the model in my laptop
           file    = "Models/2024-04-19_CountsZeroInflated/lm_Fit.rds",
           file_refit = "never")

# Add loo for model comparison
lm_Fit <- 
  add_criterion(lm_Fit, c("loo", "waic", "bayes_R2"))
```

Can you bet on what the results will be? Let's find out if you are right:

```{r}
#| label: Lm_Fit
#| include: true
#| warning: false
#| message: false

summary(lm_Fit) 
```

If you like, you can fit a frequentist model with `lm` and you will certainly get the same results. The intercept is the estimate in cell counts for the contralateral hemisphere, which in our case is the reference group. An inconsistency is evident. If we use a normal distribution, when the counts are very close to zero, and even have many zeros, the model is "forced" to predict that our hemisphere may have minus 1-2 cells (CI95% -1.5 - 3.7). Our model knows absolutely nothing about the nature of cells (which are objects that can only positive integer values). The model only does what we (wrongly) ask it to do: the fit a linear model to the data. Inadvertently, many researchers then use t-tests and ANOVAS to superimpose analysis on a model that is fundamentally illogical. Undoubtedly, we, researchers, have the capacity and the tools to do much better.

Let's plot the results using the great `TidyBayes` package [@tidybayes] by the great [Matthew Kay](https://www.mjskay.com/)

```{r}
#| label: fig-LmResults
#| include: true
#| warning: false
#| message: false
#| fig-cap: Posterior distribution for cells counts by hemisphere.
#| fig-height: 5
#| fig-width: 6

Svz_data %>%
  data_grid(Hemisphere) %>%
  add_epred_draws(lm_Fit) %>%
  ggplot(aes(x = .epred, y = Hemisphere)) +
  labs(x = "Number of cells") +
  stat_halfeye() +
  geom_vline(xintercept = 0) +
  Plot_theme
```

We can also see this inconsistency if we perform `pp?check` to compare the observation with the model predictions>

```{r}
#| label: fig-Lm_ppchek
#| include: true
#| warning: false
#| message: false
#| fig-cap: Posterior predictive checks gaussian model.
#| fig-height: 5
#| fig-width: 6

pp_check(lm_Fit, ndraws = 100) +
  labs(title = "Gaussian regression") +
  theme_classic()
```
Once again, we see irrational predictions below 0. As a scientists, I invite you to think on generative models as your main strategy to data analysis. That means, with your data, you are creating a model that could plausible have generated your data. I hope you agree with me that this linear model is not suitable for generating our cell counts; it takes impossible values below zero. Let's try to find out a better model.

## Working with a lots of zeros

A zero-inflated model defines a mixture of two separating processes. 1) A model that predicts whether or not the results is 0 and 2) a model that predicts the value of no zero results. In our case "Are there cells or not? if they are, how many?

In our case, we'll use two different distribution to work with lot's of zeros: `hurdle_poisson()` and `Zero_inflated_poisson`. Both were developed for cases when regular count models (Poisson or negative binominal) turn to be unrealistic [@feng2021a]. Loosely speaking, there are two key differences between these two. First, Zero-inflated models add an additional probability mass for obtaining zeroes. An second, as a poisson model it assumes that the variability (the distribution) of the data is the same as the mean. This implies that bigger counts are linked to bigger variability. This is not the case in many scenarios. We'll see the impact it has in our modeling strategy using `brms`.  

# Fitting a hurdle_poisson model

Let's start by using the `hurdle_poisson()` distribution in our modeling scheme: 

```{r}
#| label: HurdleFit
#| include: true
#| warning: false
#| message: false
#| results: false

Hurdle_Fit1 <- brm(Cells ~ Hemisphere, 
           data = Svz_data, 
           family = hurdle_poisson(),
           # seed for reproducibility purposes
           seed = 8807,
           control = list(adapt_delta = 0.99),
           # this is to save the model in my laptop
           file    = "Models/2024-04-19_CountsZeroInflated/Hurdle_Fit1.rds",
           file_refit = "never")

# Add loo for model comparison
Hurdle_Fit1 <- 
  add_criterion(Hurdle_Fit1, c("loo", "waic", "bayes_R2"))
```
Let's see the results using the standard summary function.

```{r}
#| label: HurdleFit_Results
#| include: true
#| warning: false
#| message: false
#| results: false

summary(Hurdle_Fit1)

```

Given the nature o the family distribution, the estimates are shown in the log scale (mu = log). The results show that the number of cells in the contralateral SVZ is exp(1.11) = 3.03. Otherwise, the ipsilateral hemisphere has about exp(1.07) = 2.91 times the number of cells. These sound logical. Now, the `hu` parameter under "Family Specific Parameters" indicates that there is a 38% probability of of observing a zero cell cunts. We'll dig a bit more in this but let's first plot the results using the great `conditional_effects` function. 

```{r}
#| label: fig-HurdleCE
#| include: true
#| warning: false
#| message: false
#| fig-cap: Conditional effects for the hurdle fit.
#| fig-height: 5
#| fig-width: 10

Hurdle_CE <- 
  conditional_effects(Hurdle_Fit1)

Hurdle_CE <- plot(Hurdle_CE, 
       plot = FALSE)[[1]]

Hurdle_Com <- Hurdle_CE + 
  Plot_theme +
  theme(legend.position = "bottom", legend.direction = "horizontal")


Hurdle_CE_hu <- 
  conditional_effects(Hurdle_Fit1, dpar = "hu")

Hurdle_CE_hu <- plot(Hurdle_CE_hu, 
       plot = FALSE)[[1]]

Hurdle_hu <- Hurdle_CE_hu + 
  Plot_theme +
  theme(legend.position = "bottom", legend.direction = "horizontal")

Hurdle_Com | Hurdle_hu
```

Now, the visualization seems more logical when we combine the two parts of the model ("mu" and "hu") (left). If this model is more consistent, we must see also more aligned prediction when using pp_check:

```{r}
#| label: fig-Hurdel_CE
#| include: true
#| warning: false
#| message: false
#| fig-cap: Posterior predictive checks hurdle model.
#| fig-height: 5
#| fig-width: 6

pp_check(Hurdle_Fit1, ndraws = 100) +
  labs(title = "Hurdle regression") +
  theme_classic()
```

As expected, our model predictions have a lower boundary at 0. 

## Modeling the dispersion of the data

Now, looking at the right graph in @fig-HurdleCE we see something that does not align with out knowledge of the subject. We now that the probability of having non-zero cunts in the SVZ of the ipsilateral hemisphere should be higher than in the contralateral. Our knowledge of the subject indicates that after an injury, the SVZ of the injured hemisphere (ipsilateral) becomes a cradle of cells where cell proliferation is abundant.As we saw in cell counts, in this region all counts are different from zero.This is one way in which scientific knowledge guides our statistical inferences. It is impractical to perform t-tests and ANOVAS without any consideration.So, can we build a more accurate model? I bet we can, and we do so by modeling also the "hu" part of the model:

```{r}
#| label: HurdleFit2
#| include: true
#| warning: false
#| message: false
#| results: false

Hurdle_Mdl2 <- bf(Cells ~ Hemisphere, 
                   hu ~ Hemisphere)
  
Hurdle_Fit2 <- brm(
           formula = Hurdle_Mdl2,
           data = Svz_data, 
           family = hurdle_poisson(),
           # seed for reproducibility purposes
           seed = 8807,
           control = list(adapt_delta = 0.99),
           # this is to save the model in my laptop
           file    = "Models/2024-04-19_CountsZeroInflated/Hurdle_Fit2.rds",
           file_refit = "never")
           

# Add loo for model comparison
Hurdle_Fit2 <- 
  add_criterion(Hurdle_Fit2, c("loo", "waic", "bayes_R2"))
```

Let's see first if the results graph aligns with out hypothesis:

```{r}
#| label: fig-HurdleCE
#| include: true
#| warning: false
#| message: false
#| fig-cap: Conditional effects for the hurdle fit.
#| fig-height: 5
#| fig-width: 10

Hurdle_CE <- 
  conditional_effects(Hurdle_Fit2)

Hurdle_CE <- plot(Hurdle_CE, 
       plot = FALSE)[[1]]

Hurdle_Com <- Hurdle_CE + 
  Plot_theme +
  theme(legend.position = "bottom", legend.direction = "horizontal")


Hurdle_CE_hu <- 
  conditional_effects(Hurdle_Fit2, dpar = "hu")

Hurdle_CE_hu <- plot(Hurdle_CE_hu, 
       plot = FALSE)[[1]]

Hurdle_hu <- Hurdle_CE_hu + 
  Plot_theme +
  theme(legend.position = "bottom", legend.direction = "horizontal")

Hurdle_Com | Hurdle_hu
```

I truly believe this model is more consistent with our knowledge of the matter and the data we have in hand. We have modeled lower counts in the contralateral hemisphere with an augmented probability (~ 75%) of seeing zeros as an outcome. Thus, our estimates have change, and I judge are now more precise. Let's see the summary and the conversion FOR THE `hu` parameters (do not look the others) to the probability scale using the `logit2prob` [function](https://sebastiansauer.github.io/convert_logit2prob/) we created at the beginning.   

```{r}
#| label: HurdleFit_Results2
#| include: true
#| warning: false
#| message: false
#| results: false

summary(Hurdle_Fit2)

logit2prob(fixef(Hurdle_Fit2))
```
Definitively, we have a new picture. Although the estimates for the number of cells are similar, the "hu" parameters (in the logit scale) tells us that the probability for seeing zeros in the contralateral hemisphere is:

$$
\text{Probability} = \frac{1}{1 + \exp(-1.34)} \approx 0.792 
$$
Indicating that there is approximately a 79.2% probability of observing zero counts in the reference hemisphere.

Conversely 

$$
\text{Probability} = \frac{1}{1 + \exp(6.04)} \approx 0.0023 
$$
Indicates a drastic reduction to about 0.23% probability of observing zero cell counts in the injured (ipsilateral) hemisphere. This is a substantial change in our estimates.

Now, let's see if a `zero_inflated_poisson()` distribution family change our conclusions. 


# Fitting a zero inflated possion model

As we saw the variations between ipsilateral and the contralateral hemispheres in our previous model, we'll model as well the two parts of the `zero_inflated_poisson()`: The count part (with a "log" link) and the excess of zeros (with a "logit" link).

```{r}
#| label: InflatedFit
#| include: true
#| warning: false
#| message: false
#| results: false


Inflated_mdl1 <- bf(Cells ~ Hemisphere,
                    zi ~ Hemisphere)

Inflated_Fit1 <- brm(
           formula = Inflated_mdl1, 
           data = Svz_data, 
           family = zero_inflated_poisson(),
           # seed for reproducibility purposes
           seed = 8807,
           control = list(adapt_delta = 0.99),
           # this is to save the model in my laptop
           file    = "Models/2024-04-19_CountsZeroInflated/Inflated_Fit.rds",
           file_refit = "never")

# Add loo for model comparison
Inflated_Fit1 <- 
  add_criterion(Inflated_Fit1, c("loo", "waic", "bayes_R2"))
```
Before we look at the results, let's carry out some basic diagnostics to compare the observations and the model predictions.

## Model diagnostics

```{r}
#| label: fig-ZeroInflatedDiag1
#| include: true
#| warning: false
#| message: false
#| fig-cap: Model diagnostics for the ordinal regression
#| fig-height: 4
#| fig-width: 5

set.seed(8807)

pp_check(Inflated_Fit1, ndraws = 100) +
  labs(title = "Zero-inflated regression") +
  theme_classic()
```

From @fig-ZeroInflatedDiag1, we can see that the predictions deviate from the observed data in a similar way. Thus, we have no major changes up to this point.

## Model results

```{r}
#| label: HurdleFit_Results
#| include: true
#| warning: false
#| message: false
#| results: false

summary(Inflated_Fit1)

logit2prob(fixef(Inflated_Fit1))

```
Well, we do see tiny changes in the estimations. The estimate for the number of cells is similar with a tiny variations in the credible intervals. The parameter for the number of zeros seem to experience a larger shift. Let-s see if it has some effect in our conclusions:

$$
\text{Probability} = \frac{1}{1 + \exp(1.21)} \approx 0.771 
$$
Indicating that there is approximately a 77% probability of observing zero counts in the reference hemisphere. Now, for the injured hemisphere we have>

$$
\text{Probability} = \frac{1}{1 + \exp(5.88)} \approx 0.0027 
$$
Indicating again a drastic reduction of observing zero cell counts in the injured (ipsilateral) hemisphere. Evaluating the results using scientific knowledge, I would say that both models provide similar sound predictions. The graphical results for our zero inflated model is as follows:

## Model plots

```{r}
#| label: fig-InflatedCE
#| include: true
#| warning: false
#| message: false
#| fig-cap: Conditional effects for the Inflated fit.
#| fig-height: 5
#| fig-width: 10

Inflated_CE <- 
  conditional_effects(Inflated_Fit1)

Inflated_CE <- plot(Inflated_CE, 
       plot = FALSE)[[1]]

Inflated_Com <- Inflated_CE + 
  Plot_theme +
  theme(legend.position = "bottom", legend.direction = "horizontal")


Inflated_CE_zi <- 
  conditional_effects(Inflated_Fit1, dpar = "zi")

Inflated_CE_zi <- plot(Inflated_CE_zi, 
       plot = FALSE)[[1]]

Inflated_zi <- Inflated_CE_zi + 
  Plot_theme +
  theme(legend.position = "bottom", legend.direction = "horizontal")

Inflated_Com | Inflated_zi
```

If we compare the the hurdle model the results are very similar. However, we can observe that the estimates for the probability of 0 in the contralateral hemisphere is wider for the hurdle model. The reason is, as I exposed at the begining, that the zero inflated model located a major probability of zeros that the `hurdle_poisson` distribution. Let's compare the model to finish the lecture. 


# Model comparison

We carry out leave-one-out cross validation using the the `loo` package [@loo; @vehtari2016]. WAIC [@gelman2013] is another approach you can explore in [this](https://medium.com/towards-data-science/do-not-over-think-about-outliers-use-a-student-t-distribution-instead-b6c584b91d5c) post.

```{r}
#| label: Models_Compare
#| include: true
#| warning: false
#| message: false
#| results: false

loo(Hurdle_Fit2, Inflated_Fit1)
```
The our of sample predictions are very similar. However, if we look at the "pareto-k-diagnostic", we see that the `hurdle_poisson` model has 1 `very bad` value, whereas this value goes to `bad` in the `zero_inflated_poisson()`. I will use this argument for staying with the second model and perform additional scientific inference from it. 

I would appreciate your comments or feedback letting me know if this journey was useful to you. If you want more quality content on data science and other topics, you might consider becoming a [medium member](https://medium.com/membership).

In the future, you can find an updated version of this post on my [GitHub site](https://github.com/daniel-manrique/MediumBlog/blob/main/2024-04-19_CountsZeroInflated.qmd).

-   All images, unless otherwise stated, were generated using the displayed R code.

# References

::: {#refs}
:::

```{r}
sessionInfo()
```
